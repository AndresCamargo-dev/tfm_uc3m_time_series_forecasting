{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsforecast\\core.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (AutoARIMA, \n",
    "                                  DynamicOptimizedTheta as DOT,\n",
    "                                  AutoETS,\n",
    "                                  AutoTheta,\n",
    "                                  WindowAverage,                              \n",
    "                                  CrostonClassic as Croston,\n",
    "                                  ADIDA,\n",
    "                                  IMAPA, \n",
    "                                  )\n",
    "from multiprocessing import cpu_count\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from prophet import Prophet\n",
    "import itertools\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook is segmented into distinct sections, which we explain below. Our primary focus lies on functions, followed by execution chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = pd.read_csv('../out/id_selection/id_selected.csv')\n",
    "id_list.set_index('unique_id', inplace=True)\n",
    "id_list = id_list.index.unique()\n",
    "id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00610101</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00610101</th>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00610101</th>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00610101</th>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00610101</th>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999777</th>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999777</th>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999777</th>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999777</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999777</th>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118847 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds      y\n",
       "unique_id                  \n",
       "00610101  2019-01-07   97.0\n",
       "00610101  2019-01-14   95.0\n",
       "00610101  2019-01-21  124.0\n",
       "00610101  2019-01-28  143.0\n",
       "00610101  2019-02-04  216.0\n",
       "...              ...    ...\n",
       "999777    2022-11-28   29.0\n",
       "999777    2022-12-05   29.0\n",
       "999777    2022-12-12   29.0\n",
       "999777    2022-12-19   29.0\n",
       "999777    2022-12-26    5.0\n",
       "\n",
       "[118847 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_selid_clean = pd.read_csv('../out/sales_files/weekly_sales_selected_loop_without_test_outliers_2019-2022.csv')\n",
    "weekly_selid_clean = weekly_selid_clean.set_index('unique_id')\n",
    "weekly_selid_clean = weekly_selid_clean[['ds', 'y']]\n",
    "weekly_selid_clean['ds'] = pd.to_datetime(weekly_selid_clean['ds'])\n",
    "weekly_selid_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_weekly_selid = weekly_selid_clean.copy()\n",
    "log_weekly_selid['y'] = np.log1p(log_weekly_selid.y)\n",
    "log_weekly_selid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation functions\n",
    "\n",
    "* Define error metrics.\n",
    "* Function for applicating error metrics to cross-validation dataframe.\n",
    "* Set of functions to obtain summary of error metrics by levels and models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_pred-y_true))\n",
    "\n",
    "def wape_mtly(y_true, y_pred): \n",
    "    wape2 = abs((y_true.sum() - y_pred.sum())) / y_true.sum() * 100\n",
    "    if np.isinf(wape2):\n",
    "        wape2 = np.nan\n",
    "    return wape2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetsforecast.losses import rmse\n",
    "\n",
    "def evaluate(cv_df):\n",
    "    cv_df.reset_index(inplace=True)\n",
    "    cv_df.set_index('unique_id', inplace = True)\n",
    "\n",
    "    columns = cv_df.drop(columns=['ds', 'cutoff']).columns.tolist()\n",
    "    exp_cv_df = cv_df.copy()  \n",
    "\n",
    "    for column in columns:\n",
    "        exp_cv_df[column] = np.expm1(cv_df[column])\n",
    "\n",
    "    metrics = pd.DataFrame(columns=['id','model','rmse', 'mae', 'wape_m'])\n",
    "    models = cv_df.drop(columns=['ds', 'cutoff', 'y']).columns.tolist()\n",
    "\n",
    "    for index in exp_cv_df.index.unique():\n",
    "        cv_one_id = exp_cv_df[exp_cv_df.index == index]\n",
    "\n",
    "        for model in models:\n",
    "            cv_one_id_model = cv_one_id[['ds','y',model]]\n",
    "            rmse_one_id_one_model = cv_one_id_model.groupby(cv_one_id_model['ds'].dt.month).apply(lambda x: rmse(x['y'], x[model]))\n",
    "            mean_rmse = rmse_one_id_one_model.mean()\n",
    "            mae_one_id_one_model = cv_one_id_model.groupby(cv_one_id_model['ds'].dt.month).apply(lambda x: mae(x['y'], x[model]))\n",
    "            mean_mae = mae_one_id_one_model.mean()\n",
    "            wape2_one_id_one_model = cv_one_id_model.groupby(cv_one_id_model['ds'].dt.month).apply(lambda x: wape_mtly(x['y'], x[model]))\n",
    "            mean_wape2 = np.nanmean(wape2_one_id_one_model)\n",
    "            row = {'id': index, \n",
    "                'model': model, \n",
    "                'rmse': round(mean_rmse),  \n",
    "                'mae': round(mean_mae,1),\n",
    "                'wape_m': round(mean_wape2,1)\n",
    "                }\n",
    "            \n",
    "            metrics = pd.concat([metrics, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics summary:\n",
    "\n",
    "In this section we defined the following procedures:\n",
    "* Select best model within each product, using MAE.\n",
    "* Create a table with descriptive metrics of each product\n",
    "* Classify WAPE of each product in levels and merge with descriptive metrics table.\n",
    "* Create final summary table: Group products in WAPE levels and compute grouped metrics\n",
    "* Count number of products per model\n",
    "* Compute global WAPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_models(df, metric):\n",
    "    min_metric_models = df.groupby('id')['mae'].idxmin()\n",
    "    best_models = df.loc[min_metric_models, ['id', 'model', 'mae', metric]]\n",
    "    column_title = f'{metric}_level'\n",
    "    best_models[column_title] = np.where(best_models[metric] == 0, '0%',\n",
    "                           np.where((best_models[metric] > 0) & (best_models[metric] <= 10), '1% - 10%',\n",
    "                           np.where((best_models[metric] > 10) & (best_models[metric] <= 20), '11% - 20%',\n",
    "                           np.where((best_models[metric] > 20) & (best_models[metric] <= 30), '21% - 30%',\n",
    "                           np.where((best_models[metric] > 30) & (best_models[metric] <= 40), '31% - 40%',\n",
    "                           np.where((best_models[metric] > 40) & (best_models[metric] <= 50), '41% - 50%',\n",
    "                           np.where((best_models[metric] > 50) & (best_models[metric] <= 60), '51% - 60%',\n",
    "                           np.where((best_models[metric] > 60) & (best_models[metric] <= 70), '61% - 70%',\n",
    "                           np.where((best_models[metric] > 70) & (best_models[metric] <= 80), '71% - 80%',\n",
    "                           np.where((best_models[metric] > 80) & (best_models[metric] <= 90), '81% - 90%',\n",
    "                           np.where((best_models[metric] > 90) & (best_models[metric] <= 100), '91% - 100%',\n",
    "                           np.where((best_models[metric] > 100), '>100%',                      \n",
    "                           'inf'))))))))))))\n",
    "    best_models.rename(columns={'id': 'unique_id'}, inplace=True)\n",
    "    best_models.set_index('unique_id', inplace=True)\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_descriptive_metrics_table():\n",
    "  summary_weekly_sales = pd.DataFrame()\n",
    "  summary_weekly_sales['mean_last_8_weeks'] = weekly_selid_clean.groupby('unique_id')['y'].rolling(window=8, min_periods=1).mean().groupby('unique_id').last()\n",
    "  summary_weekly_sales['historic_mean'] = weekly_selid_clean.groupby('unique_id')['y'].mean().round(decimals=2)\n",
    "  summary_weekly_sales['weeks_since_first_sale'] = weekly_selid_clean.groupby('unique_id')['ds'].count()\n",
    "  summary_weekly_sales['sales_2022'] = weekly_selid_clean[(weekly_selid_clean['ds'] >= '2022-01-01')].groupby('unique_id').sum()\n",
    "  return summary_weekly_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_levels(summary, best_models, metric_level):\n",
    "  error_levels = summary.merge(best_models, left_index=True, right_index=True)\n",
    "  error_levels.reset_index(inplace=True)\n",
    "  error_levels.set_index(metric_level, inplace=True)\n",
    "  return error_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_error_level_summary(weekly_error_levels, metric):\n",
    "        metric = f'{metric}_level'\n",
    "        total_sales_2022 = weekly_error_levels['sales_2022'].sum()\n",
    "        weekly_results = pd.DataFrame({metric: ['0%','1% - 10%','11% - 20%','21% - 30%','31% - 40%', '41% - 50%', '51% - 60%', '61% - 70%','71% - 80%',\n",
    "                '81% - 90%', '91% - 100%', '>100%']})\n",
    "        weekly_results.set_index(metric, inplace=True)\n",
    "        weekly_results['unique_id'] = weekly_error_levels.groupby(metric)['unique_id'].count()\n",
    "        weekly_results['mean_last_8_weeks'] = weekly_error_levels.groupby(metric)['mean_last_8_weeks'].mean().round(decimals=2)\n",
    "        weekly_results['historic_mean'] = weekly_error_levels.groupby(metric)['historic_mean'].mean().round(decimals=2)\n",
    "        weekly_results['weeks_since_first_sale'] = weekly_error_levels.groupby(metric)['weeks_since_first_sale'].mean().round(decimals=2)\n",
    "        weekly_results['sales_2022'] = weekly_error_levels.groupby(metric)['sales_2022'].sum().round(decimals=2)\n",
    "        weekly_results['% sales_2022'] = round((weekly_error_levels.groupby(metric)['sales_2022'].sum().round(decimals=2)/total_sales_2022)*100, 2)\n",
    "        #weekly_results.to_csv(f'../out/summary_tables/weekly_results_{metric}.csv')\n",
    "        return weekly_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_errors(metrics_wkl, metric):\n",
    "  best_weekly_models = select_best_models(metrics_wkl, metric)\n",
    "  best_weekly_models.sort_values(by=metric)\n",
    "  descriptive_metrics = create_descriptive_metrics_table()\n",
    "  error_levels = compute_error_levels(descriptive_metrics, best_weekly_models, f'{metric}_level')\n",
    "  results_summary = create_error_level_summary(error_levels, metric)\n",
    "  models_table = error_levels.groupby('model')['unique_id'].count().sort_values(ascending=False)\n",
    "  global_error = error_levels[metric].mean()\n",
    "\n",
    "  return results_summary, models_table, global_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Modeling\n",
    "\n",
    "In this section we defined the following functions:\n",
    "* Data transformations\n",
    "* Apply 4 models (Mean, Random Walk, Window Average, AutoArima) using cross-validation.\n",
    "* Prophet tuning with grid search for hyperparameters optimization \n",
    "* Apply prophet with cross-validation and best parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1_initial_transformations(df):\n",
    "    df = df.reset_index()\n",
    "    df = df.set_index('ds')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.sort_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1_models(df):\n",
    "        split_cv = TimeSeriesSplit(n_splits=4, test_size=4*2*1, gap=0) \n",
    "        cross_validation = pd.DataFrame()\n",
    "        \n",
    "        for train_idx, val_idx in split_cv.split(df):\n",
    "                \n",
    "                train = df.iloc[train_idx]\n",
    "                test = df.iloc[val_idx]\n",
    "                test['cutoff'] = test.index.min() - timedelta(weeks=1)\n",
    "                \n",
    "                # Mean\n",
    "                mean_model = train['y'].mean()\n",
    "                test['mean'] = mean_model\n",
    "\n",
    "                # Random Walk\n",
    "                test['random_walk'] = train.y.tail(n=1).values[0]\n",
    "                \n",
    "                # Window Average\n",
    "                train['MA4'] = train['y'].rolling(window = 4).mean()\n",
    "                test['window_average'] = train['MA4'].tail(n=1).values[0]\n",
    "\n",
    "                # ARIMA\n",
    "                target = train['y']\n",
    "                model = auto_arima(target)\n",
    "                test['auto_arima'] = model.predict(n_periods = len(test))\n",
    "\n",
    "                cross_validation = pd.concat([cross_validation, test])\n",
    "\n",
    "        return cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1_tuning_hyperparameters_prophet(df, days):\n",
    "    new_df = pd.DataFrame({'ds': df['ds'],'y':df['y']}).reset_index()\n",
    "        \n",
    "    param_grid = {  \n",
    "        'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
    "        'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "        'seasonality_mode': ['additive', 'multiplicative']\n",
    "    }\n",
    "\n",
    "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "    rmses = []  \n",
    "\n",
    "    for params in all_params:\n",
    "        m = Prophet(**params, growth='flat') \n",
    "        m.add_country_holidays(country_name='ES')\n",
    "        m.fit(new_df) \n",
    "        df_cv = cross_validation(m, initial=f'{days} days', period='56 days', horizon = '56 days', parallel=\"processes\")\n",
    "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "        rmses.append(df_p['rmse'].values[0])\n",
    "        \n",
    "    tuning_results = pd.DataFrame(all_params)\n",
    "    tuning_results['rmse'] = rmses\n",
    "\n",
    "    best_params = all_params[np.argmin(rmses)]\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1_apply_prophet(p_df, best_params, days, m1_cv):\n",
    "\n",
    "    auto_model = Prophet(changepoint_prior_scale=best_params['changepoint_prior_scale'], \n",
    "                        seasonality_prior_scale=best_params['seasonality_prior_scale'], \n",
    "                        seasonality_mode=best_params['seasonality_mode'], growth='flat')\n",
    "\n",
    "    auto_model.add_country_holidays(country_name='ES')\n",
    "    \n",
    "    auto_model.fit(p_df)\n",
    "    \n",
    "    auto_model_cv = cross_validation(auto_model, initial=f'{days} days', period='56 days', horizon = '56 days', parallel=\"processes\")\n",
    "    auto_model_cv.set_index('ds', inplace=True)\n",
    "    m1_cv['prophet'] = auto_model_cv['yhat']\n",
    "    \n",
    "    return m1_cv, auto_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to apply these 5 models the portfolio, we created a loop that iterates each function across each product.\n",
    "Finally, we:\n",
    "* Evaluate 5 models\n",
    "* Summarize metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_global_crossvalidation = pd.DataFrame()\n",
    "\n",
    "for id in log_weekly_selid.index.unique():\n",
    "\n",
    "  df = log_weekly_selid.loc[id]\n",
    "  one_id_df = m1_initial_transformations(df)\n",
    "  crossvalidation = m1_models(one_id_df)\n",
    "  days = (crossvalidation.index.min() - df['ds'].min()).days - 30\n",
    "  best_params = m1_tuning_hyperparameters_prophet(df, days)\n",
    "  crossvalidation, prophet_model = m1_apply_prophet(df, best_params, days, crossvalidation)\n",
    "  global_crossvalidation = pd.concat([global_crossvalidation, crossvalidation])\n",
    "\n",
    "m1_global_crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a pre-computed CSV files, as the execution of the loop takes several hours or even days to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m1_global_crossvalidation.to_csv('../out/cv/crossvalidation_m1_models.csv')\n",
    "m1_global_crossvalidation = pd.read_csv('../out/cv/crossvalidation_m1_models.csv')\n",
    "m1_global_crossvalidation.set_index('ds', inplace=True)\n",
    "m1_global_crossvalidation.index = pd.to_datetime(m1_global_crossvalidation.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m1_global_metrics = evaluate(m1_global_crossvalidation)\n",
    "#m1_global_metrics.to_csv('../out/metrics/m1_global_metrics.csv')\n",
    "m1_global_metrics = pd.read_csv('../out/metrics/m1_global_metrics.csv')\n",
    "#m1_global_metrics.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_results_summary, m1_models_table, m1_global_wape_m = summarize_errors(m1_global_metrics, 'wape_m')\n",
    "m1_results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_models_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_global_wape_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Modeling\n",
    "\n",
    "In this section we include:\n",
    "* Models training\n",
    "* Models evaluation using cross-validation\n",
    "* Forecasting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sf = StatsForecast(\n",
    "    models = [AutoARIMA(season_length = 52), AutoETS(season_length=52), DOT(season_length = 52), AutoTheta(season_length = 52), ADIDA(), Croston(), IMAPA(), WindowAverage(window_size=4)],\n",
    "    freq = 'W',\n",
    "    n_jobs = cpu_count()-1,\n",
    "    fallback_model= WindowAverage(window_size=4)\n",
    ")\n",
    "\n",
    "log_sf.fit(log_weekly_selid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pre-trained model for this project can be loaded, as the training process takes several hours or even days to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(log_sf, '../models/weekly_selected_log_model.pkl')\n",
    "log_sf = joblib.load('../models/weekly_selected_log_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each series was subjected to 4-blocks cross-validation with an 8-week extension for the testing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_crossvalidation_df = log_sf.cross_validation(\n",
    "    df = log_weekly_selid,\n",
    "    h = 8, \n",
    "    step_size=8, \n",
    "    n_windows=4\n",
    ")\n",
    "\n",
    "log_crossvalidation_df\n",
    "#log_crossvalidation_df.to_csv('../out/cv/crossvalidation_weekly_8_models_2019-2022_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_crossvalidation_df = pd.read_csv('../out/cv/crossvalidation_weekly_8_models_2019-2022_log.csv')\n",
    "log_crossvalidation_df.set_index('unique_id', inplace=True)\n",
    "log_crossvalidation_df['ds'] = pd.to_datetime(log_crossvalidation_df['ds'])\n",
    "log_crossvalidation_df['cutoff'] = pd.to_datetime(log_crossvalidation_df['cutoff'])\n",
    "log_crossvalidation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_global_metrics = evaluate(log_crossvalidation_df)\n",
    "#f_global_metrics.to_csv('../out/metrics/metrics_selected_weekly_exp_wape2monthly.csv')\n",
    "f_global_metrics = pd.read_csv('../out/metrics/metrics_selected_weekly_exp_wape2monthly.csv')\n",
    "f_global_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_results_summary, f_models_table, f_global_wape_m = summarize_errors(f_global_metrics, 'wape_m')\n",
    "f_results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_models_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_global_wape_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We calculated the sales forecasting that corresponds to one year (52 weeks)\n",
    "* We convert the logarithmic forecast values back to their exponential form.\n",
    "* We chart the forecasts, delineating products by their respective models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_forecast = log_sf.forecast(h=52, level=[90])\n",
    "#log_forecast.to_csv('../out/forecast/weekly_log_52_8.8.23.csv')\n",
    "\n",
    "log_forecast = pd.read_csv('../out/forecast/weekly_log_52_8.8.23.csv')\n",
    "log_forecast.set_index('unique_id', inplace=True)\n",
    "log_forecast['ds'] = pd.to_datetime(log_forecast['ds'])\n",
    "#log_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = log_forecast.drop(columns=['ds']).columns.tolist()\n",
    "f_exp_forecast = log_forecast.copy() \n",
    "\n",
    "for column in columns:\n",
    "    f_exp_forecast[column] = round(np.expm1(log_forecast[column]))\n",
    "\n",
    "f_exp_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = select_best_models(f_global_metrics, 'wape_m')\n",
    "summary = create_descriptive_metrics_table()\n",
    "merged_bmodels_summary = summary.merge(best_models, left_index=True, right_index=True).sort_values(by='historic_mean', ascending=False)\n",
    "\n",
    "models = log_crossvalidation_df.drop(columns=['ds', 'cutoff', 'y']).columns.tolist()\n",
    "model_ids = {}\n",
    "\n",
    "for model in models:\n",
    "    ids = merged_bmodels_summary[merged_bmodels_summary['model'] == model].index\n",
    "    model_ids[model] = ids\n",
    "\n",
    "model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['AutoARIMA'], unique_ids=model_ids['AutoARIMA'].values, level=[90], plot_random = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['AutoETS'], unique_ids=model_ids['AutoETS'].values, level=[90], plot_random = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['DynamicOptimizedTheta'], unique_ids=model_ids['DynamicOptimizedTheta'].values, level=[90], plot_random = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['AutoTheta'], unique_ids=model_ids['AutoTheta'].values, level=[90], plot_random = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['ADIDA'], unique_ids=model_ids['ADIDA'].values, level=[90], plot_random = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['CrostonClassic'], unique_ids=model_ids['CrostonClassic'].values, level=[90], plot_random = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['WindowAverage'], unique_ids=model_ids['WindowAverage'].values, level=[90], plot_random = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['AutoETS'], unique_ids=['9134235'], level=[90])\n",
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['AutoARIMA'], unique_ids=['9130190'], level=[90], plot_random = False)\n",
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['DynamicOptimizedTheta'], unique_ids=['29961001'], level=[90])\n",
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['AutoTheta'], unique_ids=['20010301'], level=[90], plot_random = False)\n",
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['WindowAverage'], unique_ids=['29925064'], level=[90])\n",
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['ADIDA'], unique_ids=['20735201NM'], level=[90])\n",
    "log_sf.plot(weekly_selid_clean, f_exp_forecast, models=['CrostonClassic'], unique_ids=['134617'], level=[90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Time Series Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_id = '130335'\n",
    "example_id_best_model = 'AutoARIMA'\n",
    "df_example_id = weekly_selid_clean.loc[example_id]\n",
    "log_example_id = log_weekly_selid.loc[example_id]\n",
    "StatsForecast.plot(log_example_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Group of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_df = m1_initial_transformations(log_example_id)\n",
    "ex_crossvalidation = m1_models(ex_df)\n",
    "days = (ex_crossvalidation.index.min() - log_example_id['ds'].min()).days - 30\n",
    "ex_best_params = m1_tuning_hyperparameters_prophet(log_example_id, days)\n",
    "ex_crossvalidation, prophet_model = m1_apply_prophet(log_example_id, ex_best_params, days, ex_crossvalidation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_future = prophet_model.make_future_dataframe(periods=52, freq='w')\n",
    "ex_forecast = prophet_model.predict(ex_future)\n",
    "prophet_model.plot(ex_forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model.plot_components(ex_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Group of Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sf = StatsForecast(\n",
    "    models = [AutoARIMA(season_length = 52), AutoETS(season_length=52), DOT(season_length = 52), AutoTheta(season_length = 52), ADIDA(), Croston(), IMAPA(), WindowAverage(window_size=4)],\n",
    "    freq = 'W',\n",
    "    n_jobs = cpu_count()-1,\n",
    "    fallback_model= WindowAverage(window_size=4)\n",
    ")\n",
    "\n",
    "one_sf.fit(log_example_id)\n",
    "\n",
    "one_log_cv_df = one_sf.cross_validation(\n",
    "    df = log_example_id,\n",
    "    h = 8, \n",
    "    step_size=8, \n",
    "    n_windows=4 \n",
    ")\n",
    "\n",
    "one_log_forecast = one_sf.forecast(h=52, level=[90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sf.plot(log_example_id, one_log_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = one_log_cv_df['cutoff'].unique()\n",
    "\n",
    "for k in range(len(cutoff)): \n",
    "    cv = one_log_cv_df[one_log_cv_df['cutoff'] == cutoff[k]]\n",
    "    StatsForecast.plot(log_example_id, cv.loc[:, cv.columns != 'cutoff'], models=[example_id_best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_serie_metrics = evaluate(one_log_cv_df)\n",
    "one_serie_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
