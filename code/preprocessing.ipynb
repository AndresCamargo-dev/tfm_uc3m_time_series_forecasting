{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = pd.read_csv('../in/datos_originales_empresa.csv')\n",
    "data_original.rename(columns={'material':'unique_id', 'fecha_semana':'ds', 'cantidad':'y'}, inplace=True)\n",
    "data_original.set_index('ds', inplace=True)\n",
    "data_original.index = pd.to_datetime(data_original.index)\n",
    "data_original.sort_values(by=['unique_id', 'ds'], inplace=True)\n",
    "data_original.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Complete dates & Impute zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_date_range = pd.DataFrame()\n",
    "\n",
    "for product in data_original.unique_id.unique():\n",
    "    df_one_id = data_original[data_original['unique_id'] == product]\n",
    "    new_dates = pd.date_range(df_one_id.index.min().date(), df_one_id.index.max().date(), freq='7D')\n",
    "    df_one_id = df_one_id.reindex(new_dates)\n",
    "    df_one_id['unique_id'] = product\n",
    "    df_one_id = df_one_id.fillna(0)\n",
    "    df_complete_date_range = pd.concat([df_complete_date_range, df_one_id])\n",
    "\n",
    "df_complete_date_range.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumsum_restart_zero(column):\n",
    "    cumsum = 0\n",
    "    cumsum_list = []\n",
    "    for value in column:\n",
    "        if value == 0:\n",
    "            cumsum = 0\n",
    "        cumsum += value\n",
    "        cumsum_list.append(cumsum)\n",
    "    return cumsum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_date_range['week_with_sale'] = np.where(df_complete_date_range['y'] > 0, 1, 0)\n",
    "df_complete_date_range['cumulative_weeks'] = df_complete_date_range.groupby('unique_id')['week_with_sale'].transform(cumsum_restart_zero)\n",
    "df_complete_date_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Exclude test period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_test_period = pd.DataFrame()\n",
    "\n",
    "for product in df_complete_date_range.unique_id.unique():\n",
    "    df_one_id = df_complete_date_range[df_complete_date_range['unique_id'] == product]\n",
    "    index_9w = df_one_id.index[df_one_id['cumulative_weeks']==9].min()\n",
    "    index_1w = index_9w - timedelta(weeks=8)\n",
    "    df_no_test = df_one_id[df_one_id.index >= index_1w]\n",
    "    df_without_test_period = pd.concat([df_without_test_period, df_no_test])\n",
    "\n",
    "df_without_test_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Products selection\n",
    "\n",
    "We load a pre-computed CSV file because the execution of certain steps takes several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_without_test_period.to_csv('../out/id_selection/df_without_test_period.csv')\n",
    "df_without_test_period = pd.read_csv('../out/id_selection/df_without_test_period.csv')\n",
    "df_without_test_period.rename(columns={'Unnamed: 0':'ds'}, inplace=True)\n",
    "df_without_test_period.set_index('ds', inplace=True)\n",
    "df_without_test_period.index = pd.to_datetime(df_without_test_period.index)\n",
    "df_without_test_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_without_test_period.index.max()\n",
    "t2 = t - timedelta(weeks= 8)\n",
    "\n",
    "df_without_test_period.reset_index(inplace=True)\n",
    "\n",
    "df_summary = pd.DataFrame()\n",
    "df_summary['min_date'] = df_without_test_period.groupby('unique_id')['ds'].min()\n",
    "df_summary['max_date'] = df_without_test_period.groupby('unique_id')['ds'].max()\n",
    "df_summary['lifetime'] = (df_summary['max_date'] - df_summary['min_date']).dt.days /7\n",
    "df_summary['lifetime'] = df_summary['lifetime'].round()\n",
    "df_summary['n_records'] = df_without_test_period.groupby('unique_id')['y'].count()\n",
    "df_summary['n_zero'] = df_without_test_period[df_without_test_period['y'] == 0].groupby('unique_id')['y'].count()\n",
    "df_summary['n_zero'] = df_summary['n_zero'].fillna(0)\n",
    "df_summary['% zero'] = ((df_summary['n_zero']/df_summary['n_records'])*100).round(1)\n",
    "df_summary['n_consecutive_weeks'] = df_without_test_period.groupby('unique_id')['cumulative_weeks'].max()\n",
    "df_summary['ok_zeros'] = np.where(df_summary['% zero'] < 20,1, 0)\n",
    "df_summary['ok_2years'] = np.where(df_summary['min_date'] < '2021-01-01', 1, 0)\n",
    "df_summary['ok_sales_last_2months'] = np.where(df_summary['max_date'] > t2,1, 0)\n",
    "df_summary['time_series'] = np.where((df_summary['ok_zeros'] == 1) &(df_summary['ok_2years'] == 1) & (df_summary['ok_sales_last_2months'] == 1) , 1, 0)\n",
    "\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_selected = df_summary[df_summary['time_series']==1]\n",
    "len(id_selected.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id_selected.to_csv('../out/id_selection/id_selected.csv')\n",
    "#df_summary.to_csv('../out/id_selection/ids_summary_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_without_outliers = df_without_outliers[df_without_outliers['unique_id'].isin(id_selected.index.unique())]\n",
    "df_without_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_test_period = df_without_test_period[df_without_test_period['unique_id'].isin(id_selected.index.unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Replace Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(df, target):\n",
    "    q3 = np.quantile(df[target], 0.75)\n",
    "    q1 = np.quantile(df[target], 0.25)\n",
    "    iqr = q3- q1\n",
    "    max_limit = q3 + (1.5 * iqr)\n",
    "    min_limit = q1 - (1.5 * iqr)\n",
    "    df.loc[df[target] > max_limit, target] = max_limit\n",
    "    df.loc[df[target] < min_limit, target] = min_limit\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outliers = pd.DataFrame() \n",
    "for product in df_without_test_period.unique_id.unique():\n",
    "    df_one_id = df_without_test_period[df_without_test_period['unique_id'] == product]\n",
    "    df_one_id = replace_outliers(df_one_id, 'y')\n",
    "    df_without_outliers = pd.concat([df_without_outliers, df_one_id])\n",
    "\n",
    "df_without_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outliers.reset_index(inplace=True)\n",
    "df_without_outliers.set_index('unique_id', inplace=True)\n",
    "df_without_outliers = df_without_outliers[['ds','y']]\n",
    "df_without_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Adjust Series' Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outliers = df_without_outliers[df_without_outliers['ds']>='2019-01-01']\n",
    "df_without_outliers = df_without_outliers[df_without_outliers['ds']<'2023-01-01']\n",
    "#df_without_outliers.to_csv('../out/sales_files/weekly_sales_selected_loop_without_test_outliers_2019-2022.csv')\n",
    "df_without_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Log transformation is included in the modeling file for practicality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
